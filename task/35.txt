getData:: 12500 files
getData:: 12500 files
getData::vocab size 89567
getData::cost 9.06282711029 seconds
getData:: 12500 files
getData:: 12500 files
getData::vocab size 89567
getData::cost 7.72770595551 seconds
input_IMDB_W2V:: words, dim  89567 300
input_IMDB_W2V::cost 10.7648239136 seconds
input_IMDB_W2V::embdding 89567
train: 22500  valid: 2500  test: 25000
Warning -- This is embedding_initializer function
weigth decay for  model/hidden_to_out_weight:0
weigth decay for  model/bidirectional_rnn/fw/gru_cell/gates/weights:0
weigth decay for  model/bidirectional_rnn/fw/gru_cell/candidate/weights:0
weigth decay for  model/bidirectional_rnn/bw/gru_cell/gates/weights:0
weigth decay for  model/bidirectional_rnn/bw/gru_cell/candidate/weights:0
Warning -- This is embedding_initializer function
Build graph done!
EP 1, MB 10, lr 0.0001, MB Loss= 0.7992
EP 1, MB 20, lr 0.0001, MB Loss= 0.7985
EP 1, MB 30, lr 0.0001, MB Loss= 0.7940
EP 1, MB 40, lr 0.0001, MB Loss= 0.7765
EP 1, MB 50, lr 0.0001, MB Loss= 0.7467
EP 1, MB 60, lr 0.0001, MB Loss= 0.7257
EP 1, MB 70, lr 0.0001, MB Loss= 0.6944
EP 1, MB 80, lr 0.0001, MB Loss= 0.6417
EP 1, MB 90, lr 0.0001, MB Loss= 0.6654
EP 1, MB 100, lr 0.0001, MB Loss= 0.6325
EP 1, MB 110, lr 0.0001, MB Loss= 0.6060
EP 1, MB 120, lr 0.0001, MB Loss= 0.6046
EP 1, MB 130, lr 0.0001, MB Loss= 0.5209
EP 1, MB 140, lr 0.0001, MB Loss= 0.5958
EP 1, MB 150, lr 0.0001, MB Loss= 0.5241
EP 1, MB 160, lr 0.0001, MB Loss= 0.5057
EP 1, MB 170, lr 0.0001, MB Loss= 0.5586
EP 1, MB 180, lr 0.0001, MB Loss= 0.5136
EP 1, MB 190, lr 0.0001, MB Loss= 0.5684
EP 1, MB 200, lr 0.0001, MB Loss= 0.5516
EP 1, MB 210, lr 0.0001, MB Loss= 0.5218
EP 1, MB 220, lr 0.0001, MB Loss= 0.5391
Train Loss:  0.5256 Test Loss:  0.5315 Train Accuracy:  0.7844 Test Accuracy:  0.7772


EP 2, MB 5, lr 0.0001, MB Loss= 0.5910
EP 2, MB 15, lr 0.0001, MB Loss= 0.5751
EP 2, MB 25, lr 0.0001, MB Loss= 0.5212
EP 2, MB 35, lr 0.0001, MB Loss= 0.5264
EP 2, MB 45, lr 0.0001, MB Loss= 0.5426
EP 2, MB 55, lr 0.0001, MB Loss= 0.4442
EP 2, MB 65, lr 0.0001, MB Loss= 0.5351
EP 2, MB 75, lr 0.0001, MB Loss= 0.5848
EP 2, MB 85, lr 0.0001, MB Loss= 0.4781
EP 2, MB 95, lr 0.0001, MB Loss= 0.4958
EP 2, MB 105, lr 0.0001, MB Loss= 0.4887
EP 2, MB 115, lr 0.0001, MB Loss= 0.6019
EP 2, MB 125, lr 0.0001, MB Loss= 0.5373
EP 2, MB 135, lr 0.0001, MB Loss= 0.5913
EP 2, MB 145, lr 0.0001, MB Loss= 0.5075
EP 2, MB 155, lr 0.0001, MB Loss= 0.5114
EP 2, MB 165, lr 0.0001, MB Loss= 0.5097
EP 2, MB 175, lr 0.0001, MB Loss= 0.5172
EP 2, MB 185, lr 0.0001, MB Loss= 0.5342
EP 2, MB 195, lr 0.0001, MB Loss= 0.4869
EP 2, MB 205, lr 0.0001, MB Loss= 0.4302
EP 2, MB 215, lr 0.0001, MB Loss= 0.4164
EP 2, MB 225, lr 0.0001, MB Loss= 0.5239
Train Loss:  0.4935 Test Loss:  0.4976 Train Accuracy:  0.8004 Test Accuracy:  0.7976


EP 3, MB 10, lr 0.0001, MB Loss= 0.4315
EP 3, MB 20, lr 0.0001, MB Loss= 0.4729
EP 3, MB 30, lr 0.0001, MB Loss= 0.5020
EP 3, MB 40, lr 0.0001, MB Loss= 0.5269
EP 3, MB 50, lr 0.0001, MB Loss= 0.4961
EP 3, MB 60, lr 0.0001, MB Loss= 0.5107
EP 3, MB 70, lr 0.0001, MB Loss= 0.4871
EP 3, MB 80, lr 0.0001, MB Loss= 0.4585
EP 3, MB 90, lr 0.0001, MB Loss= 0.4914
EP 3, MB 100, lr 0.0001, MB Loss= 0.5106
EP 3, MB 110, lr 0.0001, MB Loss= 0.5076
EP 3, MB 120, lr 0.0001, MB Loss= 0.4483
EP 3, MB 130, lr 0.0001, MB Loss= 0.5246
EP 3, MB 140, lr 0.0001, MB Loss= 0.5346
EP 3, MB 150, lr 0.0001, MB Loss= 0.3534
EP 3, MB 160, lr 0.0001, MB Loss= 0.4440
EP 3, MB 170, lr 0.0001, MB Loss= 0.4309
EP 3, MB 180, lr 0.0001, MB Loss= 0.5111
EP 3, MB 190, lr 0.0001, MB Loss= 0.4741
EP 3, MB 200, lr 0.0001, MB Loss= 0.4216
EP 3, MB 210, lr 0.0001, MB Loss= 0.4871
EP 3, MB 220, lr 0.0001, MB Loss= 0.4623
Train Loss:  0.4584 Test Loss:  0.4612 Train Accuracy:  0.8277 Test Accuracy:  0.8241


Optimization Finished!
session recovering... loading the best parameters...
session recovered!
Train Accuracy:  0.8277 Test Accuracy:  0.8241
